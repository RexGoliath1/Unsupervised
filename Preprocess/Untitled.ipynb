{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = pd.read_csv('/home/sgoncia/Documents/Github/Unsupervised/Santander/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, var3, var15, imp_ent_var16_ult1, imp_op_var39_comer_ult1, imp_op_var39_comer_ult3, imp_op_var40_comer_ult1, imp_op_var40_comer_ult3, imp_op_var40_efect_ult1, imp_op_var40_efect_ult3, imp_op_var40_ult1, imp_op_var41_comer_ult1, imp_op_var41_comer_ult3, imp_op_var41_efect_ult1, imp_op_var41_efect_ult3, imp_op_var41_ult1, imp_op_var39_efect_ult1, imp_op_var39_efect_ult3, imp_op_var39_ult1, imp_sal_var16_ult1, ind_var1_0, ind_var1, ind_var2_0, ind_var2, ind_var5_0, ind_var5, ind_var6_0, ind_var6, ind_var8_0, ind_var8, ind_var12_0, ind_var12, ind_var13_0, ind_var13_corto_0, ind_var13_corto, ind_var13_largo_0, ind_var13_largo, ind_var13_medio_0, ind_var13_medio, ind_var13, ind_var14_0, ind_var14, ind_var17_0, ind_var17, ind_var18_0, ind_var18, ind_var19, ind_var20_0, ind_var20, ind_var24_0, ind_var24, ind_var25_cte, ind_var26_0, ind_var26_cte, ind_var26, ind_var25_0, ind_var25, ind_var27_0, ind_var28_0, ind_var28, ind_var27, ind_var29_0, ind_var29, ind_var30_0, ind_var30, ind_var31_0, ind_var31, ind_var32_cte, ind_var32_0, ind_var32, ind_var33_0, ind_var33, ind_var34_0, ind_var34, ind_var37_cte, ind_var37_0, ind_var37, ind_var39_0, ind_var40_0, ind_var40, ind_var41_0, ind_var41, ind_var39, ind_var44_0, ind_var44, ind_var46_0, ind_var46, num_var1_0, num_var1, num_var4, num_var5_0, num_var5, num_var6_0, num_var6, num_var8_0, num_var8, num_var12_0, num_var12, num_var13_0, num_var13_corto_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 371 columns]\n",
      "(76020, 371)\n"
     ]
    }
   ],
   "source": [
    "cols = t1.head(0)\n",
    "print(cols)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c3c1ea2f3298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Series' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.arange(t1.shape[1])\n",
    "a_t = np.transpose(a)\n",
    "t1['new'] = Series(a_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [saldo_medio_var17_hace3, var38, num_meses_var13_medio_ult3]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "t2 = t1[['saldo_medio_var17_hace3','var38','num_meses_var13_medio_ult3']]\n",
    "t3 = t1[['saldo_medio_var29_hace2','var3','num_meses_var13_medio_ult3']]\n",
    "print(t2.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tuple1:  1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/pandas/core/frame.py:2378: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7db8f9ec73a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Size of tuple1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Size of train4: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtrain4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testlabel'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
     ]
    }
   ],
   "source": [
    "# Tuples to reorg\n",
    "tuple1 = ['test1,test2,test3']\n",
    "tuple2 = ['test1','test1','test2','test2','test3']\n",
    "\n",
    "# Adding label for attempted merge\n",
    "train3 = train2.head(5)\n",
    "train3['testlabel'] = tuple2\n",
    "\n",
    "# Add second label\n",
    "print('Size of tuple1: ', len(tuple1), '\\n')\n",
    "train4 = train2.head(3)\n",
    "print('Size of train4: ', train4.size(), '\\n')\n",
    "train4['testlabel'] = tuple1\n",
    "\n",
    "print('Train3 Head:\\n',train3.head(5))\n",
    "print('Train4 Head:\\n',train4.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN_PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_pandas\n",
    "from sklearn_pandas import dataframe_mapper\n",
    "from sklearn_pandas import cross_validation\n",
    "from sklearn_pandas import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn_pandas:\n",
      "\n",
      "NAME\n",
      "    sklearn_pandas\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cross_validation\n",
      "    dataframe_mapper\n",
      "    pipeline\n",
      "\n",
      "VERSION\n",
      "    1.3.0\n",
      "\n",
      "FILE\n",
      "    /home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/sklearn_pandas/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn_pandas.dataframe_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn_pandas.dataframe_mapper in sklearn_pandas:\n",
      "\n",
      "NAME\n",
      "    sklearn_pandas.dataframe_mapper\n",
      "\n",
      "CLASSES\n",
      "    sklearn.base.BaseEstimator(builtins.object)\n",
      "        DataFrameMapper(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "    sklearn.base.TransformerMixin(builtins.object)\n",
      "        DataFrameMapper(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "    \n",
      "    class DataFrameMapper(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "     |  Map Pandas data frame column subsets to their own\n",
      "     |  sklearn transformation.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DataFrameMapper\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, features, default=False, sparse=False, df_out=False)\n",
      "     |      Params:\n",
      "     |      \n",
      "     |      features    a list of pairs. The first element is the pandas column\n",
      "     |                  selector. This can be a string (for one column) or a list\n",
      "     |                  of strings. The second element is an object that supports\n",
      "     |                  sklearn's transform interface, or a list of such objects.\n",
      "     |      \n",
      "     |      default     default transformer to apply to the columns not\n",
      "     |                  explicitly selected in the mapper. If False (default),\n",
      "     |                  discard them. If None, pass them through untouched. Any\n",
      "     |                  other transformer will be applied to all the unselected\n",
      "     |                  columns as a whole, taken as a 2d-array.\n",
      "     |      \n",
      "     |      sparse      will return sparse matrix if set True and any of the\n",
      "     |                  extracted features is sparse. Defaults to False.\n",
      "     |      \n",
      "     |      df_out      return a pandas data frame, with each column named using\n",
      "     |                  the pandas column that created it (if there's only one\n",
      "     |                  input and output) or the input columns joined with '_'\n",
      "     |                  if there's multiple inputs, and the name concatenated with\n",
      "     |                  '_1', '_2' etc if there's multiple outputs. NB: does not\n",
      "     |                  work if *default* or *sparse* are true\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit a transformation from the pipeline\n",
      "     |      \n",
      "     |      X       the data to fit\n",
      "     |      \n",
      "     |      y       the target vector relative to X, optional\n",
      "     |  \n",
      "     |  get_names(self, c, t, x)\n",
      "     |      Return verbose names for the transformed columns.\n",
      "     |      \n",
      "     |      c       name (or list of names) of the original column(s)\n",
      "     |      t       transformer\n",
      "     |      x       transformed columns (numpy.ndarray)\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Transform the given data. Assumes that fit has already been called.\n",
      "     |      \n",
      "     |      X       the data to transform\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep: boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The former have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |  \n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |      \n",
      "     |      Fits transformer to X and y with optional parameters fit_params\n",
      "     |      and returns a transformed version of X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape [n_samples, n_features]\n",
      "     |          Training set.\n",
      "     |      \n",
      "     |      y : numpy array of shape [n_samples]\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      "     |          Transformed array.\n",
      "\n",
      "FILE\n",
      "    /home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/sklearn_pandas/dataframe_mapper.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataframe_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn_pandas.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn_pandas.cross_validation in sklearn_pandas:\n",
      "\n",
      "NAME\n",
      "    sklearn_pandas.cross_validation\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        DataWrapper\n",
      "    sklearn.grid_search.GridSearchCV(sklearn.grid_search.BaseSearchCV)\n",
      "        GridSearchCV\n",
      "    sklearn.grid_search.RandomizedSearchCV(sklearn.grid_search.BaseSearchCV)\n",
      "        RandomizedSearchCV\n",
      "    \n",
      "    class DataWrapper(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, df)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GridSearchCV(sklearn.grid_search.GridSearchCV)\n",
      "     |  Exhaustive search over specified parameter values for an estimator.\n",
      "     |  \n",
      "     |  Important members are fit, predict.\n",
      "     |  \n",
      "     |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated grid-search over a parameter grid.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      A object of that type is instantiated for each grid point.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_grid : dict or list of dictionaries\n",
      "     |      Dictionary with parameters names (string) as keys and lists of\n",
      "     |      parameter settings to try as values, or a list of such\n",
      "     |      dictionaries, in which case the grids spanned by each dictionary\n",
      "     |      in the list are explored. This enables searching over any sequence\n",
      "     |      of parameter settings.\n",
      "     |  \n",
      "     |  scoring : string, callable or None, default=None\n",
      "     |      A string (see model evaluation documentation) or\n",
      "     |      a scorer callable object / function with signature\n",
      "     |      ``scorer(estimator, X, y)``.\n",
      "     |      If ``None``, the ``score`` method of the estimator is used.\n",
      "     |  \n",
      "     |  fit_params : dict, optional\n",
      "     |      Parameters to pass to the fit method.\n",
      "     |  \n",
      "     |  n_jobs : int, default=1\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.17\n",
      "     |         Upgraded to joblib 0.9.3.\n",
      "     |  \n",
      "     |  pre_dispatch : int, or string, optional\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A string, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : boolean, default=True\n",
      "     |      If True, the data is assumed to be identically distributed across\n",
      "     |      the folds, and the loss minimized is the total loss per sample,\n",
      "     |      and not the mean loss across the folds.\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, optional\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 3-fold cross-validation,\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - An object to be used as a cross-validation generator.\n",
      "     |      - An iterable yielding train/test splits.\n",
      "     |  \n",
      "     |      For integer/None inputs, if ``y`` is binary or multiclass,\n",
      "     |      :class:`StratifiedKFold` used. If the estimator is a classifier\n",
      "     |      or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |  refit : boolean, default=True\n",
      "     |      Refit the best estimator with the entire dataset.\n",
      "     |      If \"False\", it is impossible to make predictions using\n",
      "     |      this GridSearchCV instance after fitting.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  error_score : 'raise' (default) or numeric\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import svm, grid_search, datasets\n",
      "     |  >>> iris = datasets.load_iris()\n",
      "     |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "     |  >>> svr = svm.SVC()\n",
      "     |  >>> clf = grid_search.GridSearchCV(svr, parameters)\n",
      "     |  >>> clf.fit(iris.data, iris.target)\n",
      "     |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      "     |  GridSearchCV(cv=None, error_score=...,\n",
      "     |         estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n",
      "     |                       decision_function_shape=None, degree=..., gamma=...,\n",
      "     |                       kernel='rbf', max_iter=-1, probability=False,\n",
      "     |                       random_state=None, shrinking=True, tol=...,\n",
      "     |                       verbose=False),\n",
      "     |         fit_params={}, iid=..., n_jobs=1,\n",
      "     |         param_grid=..., pre_dispatch=..., refit=...,\n",
      "     |         scoring=..., verbose=...)\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  grid_scores_ : list of named tuples\n",
      "     |      Contains scores for all parameter combinations in param_grid.\n",
      "     |      Each entry corresponds to one parameter setting.\n",
      "     |      Each named tuple has the attributes:\n",
      "     |  \n",
      "     |          * ``parameters``, a dict of parameter settings\n",
      "     |          * ``mean_validation_score``, the mean score over the\n",
      "     |            cross-validation folds\n",
      "     |          * ``cv_validation_scores``, the list of scores for each fold\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if refit=False.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Score of best_estimator on the left out data.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |  scorer_ : function\n",
      "     |      Scorer function used on the held out data to choose the best\n",
      "     |      parameters for the model.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  ------\n",
      "     |  The parameters selected are those that maximize the score of the left out\n",
      "     |  data, unless an explicit score is passed in which case it is used instead.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  ---------\n",
      "     |  :class:`ParameterGrid`:\n",
      "     |      generates all the combinations of a an hyperparameter grid.\n",
      "     |  \n",
      "     |  :func:`sklearn.cross_validation.train_test_split`:\n",
      "     |      utility function to split the data into a development set usable\n",
      "     |      for fitting a GridSearchCV instance and an evaluation set for\n",
      "     |      its final evaluation.\n",
      "     |  \n",
      "     |  :func:`sklearn.metrics.make_scorer`:\n",
      "     |      Make a scorer from a performance metric or loss function.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GridSearchCV\n",
      "     |      sklearn.grid_search.GridSearchCV\n",
      "     |      sklearn.grid_search.BaseSearchCV\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, *params, **kwparams)\n",
      "     |      Run fit with all sets of parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      X : array-like, shape = [n_samples, n_features]\n",
      "     |          Training vector, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |  \n",
      "     |  predict(self, X, *params, **kwparams)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.grid_search.BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements ``inverse_transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = [n_samples, n_features]\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |       * The long-standing behavior of this method changed in version 0.16.\n",
      "     |       * It no longer uses the metric provided by ``estimator.score`` if the\n",
      "     |         ``scoring`` parameter was set when fitting.\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep: boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The former have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomizedSearchCV(sklearn.grid_search.RandomizedSearchCV)\n",
      "     |  Randomized search on hyper parameters.\n",
      "     |  \n",
      "     |  \n",
      "     |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated search over parameter settings.\n",
      "     |  \n",
      "     |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      "     |  rather a fixed number of parameter settings is sampled from the specified\n",
      "     |  distributions. The number of parameter settings that are tried is\n",
      "     |  given by n_iter.\n",
      "     |  \n",
      "     |  If all parameters are presented as a list,\n",
      "     |  sampling without replacement is performed. If at least one parameter\n",
      "     |  is given as a distribution, sampling with replacement is used.\n",
      "     |  It is highly recommended to use continuous distributions for continuous\n",
      "     |  parameters.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      A object of that type is instantiated for each grid point.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_distributions : dict\n",
      "     |      Dictionary with parameters names (string) as keys and distributions\n",
      "     |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "     |      method for sampling (such as those from scipy.stats.distributions).\n",
      "     |      If a list is given, it is sampled uniformly.\n",
      "     |  \n",
      "     |  n_iter : int, default=10\n",
      "     |      Number of parameter settings that are sampled. n_iter trades\n",
      "     |      off runtime vs quality of the solution.\n",
      "     |  \n",
      "     |  scoring : string, callable or None, default=None\n",
      "     |      A string (see model evaluation documentation) or\n",
      "     |      a scorer callable object / function with signature\n",
      "     |      ``scorer(estimator, X, y)``.\n",
      "     |      If ``None``, the ``score`` method of the estimator is used.\n",
      "     |  \n",
      "     |  fit_params : dict, optional\n",
      "     |      Parameters to pass to the fit method.\n",
      "     |  \n",
      "     |  n_jobs : int, default=1\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |  \n",
      "     |  pre_dispatch : int, or string, optional\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A string, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : boolean, default=True\n",
      "     |      If True, the data is assumed to be identically distributed across\n",
      "     |      the folds, and the loss minimized is the total loss per sample,\n",
      "     |      and not the mean loss across the folds.\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, optional\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 3-fold cross-validation,\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - An object to be used as a cross-validation generator.\n",
      "     |      - An iterable yielding train/test splits.\n",
      "     |  \n",
      "     |      For integer/None inputs, if ``y`` is binary or multiclass,\n",
      "     |      :class:`StratifiedKFold` used. If the estimator is a classifier\n",
      "     |      or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |  refit : boolean, default=True\n",
      "     |      Refit the best estimator with the entire dataset.\n",
      "     |      If \"False\", it is impossible to make predictions using\n",
      "     |      this RandomizedSearchCV instance after fitting.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  random_state : int or RandomState\n",
      "     |      Pseudo random number generator state used for random uniform sampling\n",
      "     |      from lists of possible values instead of scipy.stats distributions.\n",
      "     |  \n",
      "     |  error_score : 'raise' (default) or numeric\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  grid_scores_ : list of named tuples\n",
      "     |      Contains scores for all parameter combinations in param_grid.\n",
      "     |      Each entry corresponds to one parameter setting.\n",
      "     |      Each named tuple has the attributes:\n",
      "     |  \n",
      "     |          * ``parameters``, a dict of parameter settings\n",
      "     |          * ``mean_validation_score``, the mean score over the\n",
      "     |            cross-validation folds\n",
      "     |          * ``cv_validation_scores``, the list of scores for each fold\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if refit=False.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Score of best_estimator on the left out data.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The parameters selected are those that maximize the score of the held-out\n",
      "     |  data, according to the scoring parameter.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  :class:`GridSearchCV`:\n",
      "     |      Does exhaustive search over a grid of parameters.\n",
      "     |  \n",
      "     |  :class:`ParameterSampler`:\n",
      "     |      A generator over parameter settins, constructed from\n",
      "     |      param_distributions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomizedSearchCV\n",
      "     |      sklearn.grid_search.RandomizedSearchCV\n",
      "     |      sklearn.grid_search.BaseSearchCV\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, *params, **kwparams)\n",
      "     |      Run fit on the estimator with randomly drawn parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = [n_samples, n_features]\n",
      "     |          Training vector, where n_samples in the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |  \n",
      "     |  predict(self, X, *params, **kwparams)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.grid_search.BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements ``inverse_transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = [n_samples, n_features]\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |       * The long-standing behavior of this method changed in version 0.16.\n",
      "     |       * It no longer uses the metric provided by ``estimator.score`` if the\n",
      "     |         ``scoring`` parameter was set when fitting.\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep: boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The former have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    cross_val_score(model, X, *args, **kwargs)\n",
      "\n",
      "DATA\n",
      "    DEPRECATION_MSG = '\\n    Custom cross-validation compatibility shims.....\n",
      "\n",
      "FILE\n",
      "    /home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/sklearn_pandas/cross_validation.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn_pandas.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn_pandas.pipeline in sklearn_pandas:\n",
      "\n",
      "NAME\n",
      "    sklearn_pandas.pipeline\n",
      "\n",
      "CLASSES\n",
      "    sklearn.pipeline.Pipeline(sklearn.base.BaseEstimator)\n",
      "        TransformerPipeline\n",
      "    \n",
      "    class TransformerPipeline(sklearn.pipeline.Pipeline)\n",
      "     |  Pipeline that expects all steps to be transformers taking a single X argument,\n",
      "     |  an optional y argument,\n",
      "     |  and having fit and transform methods.\n",
      "     |  \n",
      "     |  Code is copied from sklearn's Pipeline\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TransformerPipeline\n",
      "     |      sklearn.pipeline.Pipeline\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, steps)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, **fit_params)\n",
      "     |      Fit all the transforms one after the other and transform the\n",
      "     |      data, then fit the transformed data using the final estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Training data. Must fulfill input requirements of first step of the\n",
      "     |          pipeline.\n",
      "     |      y : iterable, default=None\n",
      "     |          Training targets. Must fulfill label requirements for all steps of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit all the transforms one after the other and transform the\n",
      "     |      data, then use fit_transform on transformed data using the final\n",
      "     |      estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Training data. Must fulfill input requirements of first step of the\n",
      "     |          pipeline.\n",
      "     |      \n",
      "     |      y : iterable, default=None\n",
      "     |          Training targets. Must fulfill label requirements for all steps of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.pipeline.Pipeline:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Applies transforms to the data, and the decision_function method of\n",
      "     |      the final estimator. Valid only if the final estimator implements\n",
      "     |      decision_function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to predict on. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  fit_predict(self, X, y=None, **fit_params)\n",
      "     |      Applies fit_predict of last step in pipeline after transforms.\n",
      "     |      \n",
      "     |      Applies fit_transforms of a pipeline to the data, followed by the\n",
      "     |      fit_predict method of the final estimator in the pipeline. Valid\n",
      "     |      only if the final estimator implements fit_predict.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Training data. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |      y : iterable, default=None\n",
      "     |          Training targets. Must fulfill label requirements for all steps\n",
      "     |          of the pipeline.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep: boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  inverse_transform(self, X)\n",
      "     |      Applies inverse transform to the data.\n",
      "     |      Starts with the last step of the pipeline and applies ``inverse_transform`` in\n",
      "     |      inverse order of the pipeline steps.\n",
      "     |      Valid only if all steps of the pipeline implement inverse_transform.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to inverse transform. Must fulfill output requirements of the\n",
      "     |          last step of the pipeline.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Applies transforms to the data, and the predict method of the\n",
      "     |      final estimator. Valid only if the final estimator implements\n",
      "     |      predict.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to predict on. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Applies transforms to the data, and the predict_log_proba method of\n",
      "     |      the final estimator. Valid only if the final estimator implements\n",
      "     |      predict_log_proba.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to predict on. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Applies transforms to the data, and the predict_proba method of the\n",
      "     |      final estimator. Valid only if the final estimator implements\n",
      "     |      predict_proba.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to predict on. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Applies transforms to the data, and the score method of the\n",
      "     |      final estimator. Valid only if the final estimator implements\n",
      "     |      score.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to score. Must fulfill input requirements of first step of the\n",
      "     |          pipeline.\n",
      "     |      \n",
      "     |      y : iterable, default=None\n",
      "     |          Targets used for scoring. Must fulfill label requirements for all steps of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Applies transforms to the data, and the transform method of the\n",
      "     |      final estimator. Valid only if the final estimator implements\n",
      "     |      transform.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : iterable\n",
      "     |          Data to predict on. Must fulfill input requirements of first step of\n",
      "     |          the pipeline.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.pipeline.Pipeline:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  named_steps\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The former have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    make_transformer_pipeline(*steps)\n",
      "        Construct a TransformerPipeline from the given estimators.\n",
      "\n",
      "FILE\n",
      "    /home/sgoncia/anaconda3/envs/sgoncia/lib/python3.5/site-packages/sklearn_pandas/pipeline.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sgoncia]",
   "language": "python",
   "name": "conda-env-sgoncia-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
